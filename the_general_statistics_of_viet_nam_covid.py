# -*- coding: utf-8 -*-
"""The General Statistics of Viet Nam Covid

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bMB0feNDhNO0gj6SzrZ1m2gfFlIj8DQZ

# The General Statistics of Viet Nam Covid

Viet Nam has been through a tough time in 2021, although they dealt with it very well in 2020, with almost only 35 death cases while the whole world suffered a significant impact. Therefore, we would like to deepen our understanding of the reason for this issue. We will crawl Viet Nam Covid data such as cases, deaths, etc from a website. From these, we calculate its rate and figure out its impact on various entities and at different times. We will compare rates that happened between the day of the week, months, and evaluate which month or weekday has the highest rate. In conclusion, we could recommend those hospitals may increase their staffs on a specific day of the week, or make other possible decisions.
"""

# import library
import requests
import calendar
import pandas as pd
from bs4 import BeautifulSoup
from datetime import date, datetime, timedelta

"""Firstly, we have tried to crawl some data from covid19.who.int, ourworldindata, etc. Nevertheless, they showed data through charts, graphs or general data, whilst we needed detailed daily data with specific and exact numbers. After researched, we decided to use the data from Wikipedia, which was summarized by the table."""

# crawl information from wikipedia website
# ping a website and return the HTML 
website_url = requests.get('https://en.m.wikipedia.org/wiki/COVID-19_pandemic_in_Vietnam').text
soup = BeautifulSoup(website_url,'lxml')

# accessing HTML tags to locate the table - Timeline
table = soup.find('div',{'class':'barbox tright'})
rows = table.findAll('tr',{'class':'mw-collapsible mw-collapsed'})

"""To crawl data from the website, we used the method find and findAll to access HTML tags to find the table we want. Since there were some tags with the same name, we had to use a for loop to access all of these HTML tags without omission.


Found out missing data and temporarily removed rows included it. Added residual data to a temporary data frame.

After crawled data from a website to a data frame, we realized there were some unknown and unclear data. For instance, there were no obvious data from 24-01-2020 and 27-01-2020, to fix this problem we tried to fill all these data with the same previous data. In this way, we would not miss any data from the beginning and enhance the prediction's probability.
"""

# using for loop since there are different tags with the same name
tempDataFrame = []
for i in rows:
  dates = str(i.find('td',{'colspan':"2"},{'class':"bb-c"}).string)
  cases = int(i.find('span',{'class':"mcc-rx"}).string.replace(',',''))
  deaths = int(i.find('span',{'class':"mcc-rm"}).string.replace(',',''))

# temporary remove rows with unclear information and append it to a dataframe
  if dates!="â‹®":
    tmp_row = {
    "date" : dates,
    "case" : cases,
    "death" : deaths
    }
    tempDataFrame.append(tmp_row)
df = pd.DataFrame(tempDataFrame)

# convert date dataframe with string type to datetime type
df["date"] = pd.to_datetime(df["date"])

"""Created a date dataframe, fill it with full dates by using the max-min method. Then merged it with the unknown filled dataframe and sorted it. And removed all NaN values. """

# create date dataframe and fill unknown dates. 
# determine all dates based on the beginning day and ending day
date_df = pd.DataFrame({"date" : pd.date_range(start=df["date"].min(), end=df["date"].max())})

# merge 2 dataframes 
final = pd.merge(
    date_df,
    df,
    how="left",
    left_on="date",
    right_on="date",
)

# sorted dates
final.sort_values("date")

# fill NaN values
final = final.fillna(method='ffill')
final

"""Although the original table from the website had its case and death rates data, but we decided to calculate it again to analyse other needed data easier in our way. 

Principle for calculating both case and death rates:

$$Case.and.death.rates = \frac{previous. number - current. number}{current. number*100}$$

After calculated, we added results to 2 different columns in the available dataframe.

"""

# calculate percentages of case rates 
case_rates_percent = 0
case_rates_list = [0]
final["case rate"] = case_rates_percent
for current_number,previous_number in zip(final['case'],final['case'][1:]):
  case_rates_percent = round((previous_number - current_number)/current_number*100)
  case_rates_list.append(case_rates_percent)
final["case rate"] = case_rates_list

# calculate percentages of death rates
death_rates_percent = 0
death_rates_list = [0]
final["death rate"] = death_rates_percent
for current_number_d,previous_number_d in zip(final["death"],final["death"][1:]):
  death_rates_percent = round((previous_number_d - current_number_d)/current_number_d*100)if current_number_d else 0
  death_rates_list.append(death_rates_percent)
final["death rate"] = death_rates_list

# review dataframe information such as datatypes and its index
final.info()

"""Based on the date data, we converted it to weeks and months. Then calculated mean of case and death rates and grouped by weekdays and months. Finally, ploted these data to 2 line graphs to compare its impact on various weekdays and months."""

week = []
month = []
#  convert date and time objects to their string representation: weeks and months
for date in final['date']:
  week.append(date.strftime('%A'))
  month.append(date.strftime('%m'))
# append weeks and months to dataframes
final["week"] = week
final["month"] = month

# define a list with 7 days of week
days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']
# define a list with 12 months 
months = ['01','02','03','04','05','06','07','08','09','10','11','12']

# indexing and grouping based on days of week's and months' order as 2 dataframes
week_df = final.groupby('week').mean().reindex(days)
month_df = final.groupby('month').mean().reindex(months)
print(week_df)
print(month_df)

# plot 2 dataframes by weeks and months
y =["case rate", "death rate"] 
week_df.plot(y=y)
month_df.plot(y=y)

"""In conclusion, we can see that cases happened with high volumn on Thursday, Friday. Death cases usually happened in July, August. """